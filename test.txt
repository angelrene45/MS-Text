import psutil
import time
import logging
from prometheus_client import start_http_server, Gauge
from opentelemetry import trace
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import BatchSpanProcessor
from opentelemetry.exporter.jaeger import JaegerExporter
from opentelemetry.sdk.resources import Resource

# Set up logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Set up OpenTelemetry with Jaeger Exporter
resource = Resource(attributes={"service.name": "memory-monitor"})
trace.set_tracer_provider(TracerProvider(resource=resource))
tracer = trace.get_tracer(__name__)

jaeger_exporter = JaegerExporter(
    agent_host_name="localhost",  # Set the Jaeger server address if needed
    agent_port=6831,
)

span_processor = BatchSpanProcessor(jaeger_exporter)
trace.get_tracer_provider().add_span_processor(span_processor)

# Prometheus metric for total memory usage
total_memory_usage = Gauge('total_memory_usage_percent', 'Total Memory usage percentage')

# Set memory usage thresholds for different levels of alerts
LOW_THRESHOLD = 70  # 70% memory usage - initial threshold
HIGH_THRESHOLD = 85  # 85% memory usage - higher threshold
CRITICAL_THRESHOLD = 90  # 90% memory usage - critical threshold
TOP_N = 5  # Set the top N processes to capture

# Dictionary to track processes that have already been traced
traced_processes = {}

# Time limit in seconds before re-tracing the same process
REFRESH_INTERVAL = 600  # 10 minutes

# Function to monitor system memory usage and update Prometheus metrics
def monitor_memory():
    total_memory = psutil.virtual_memory().percent
    
    # Update the Prometheus metric for total memory usage
    total_memory_usage.set(total_memory)
    
    # Log total memory usage
    logger.info(f"Total memory usage: {total_memory}%")

    # Capture top N process information based on different thresholds
    if total_memory > CRITICAL_THRESHOLD:
        logger.critical(f"Memory usage exceeded {CRITICAL_THRESHOLD}%: {total_memory}%")
        create_aggregated_trace(CRITICAL_THRESHOLD)
    elif total_memory > HIGH_THRESHOLD:
        logger.warning(f"Memory usage exceeded {HIGH_THRESHOLD}%: {total_memory}%")
        create_aggregated_trace(HIGH_THRESHOLD)
    elif total_memory > LOW_THRESHOLD:
        logger.info(f"Memory usage exceeded {LOW_THRESHOLD}%: {total_memory}%")
        create_aggregated_trace(LOW_THRESHOLD)

# Function to create an aggregated trace for processes above the memory threshold
def create_aggregated_trace(threshold):
    logger.info(f"Capturing top {TOP_N} processes with memory usage above {threshold}%...")

    # Get all processes sorted by memory usage, and take the top N
    processes = sorted(psutil.process_iter(['pid', 'name', 'memory_percent', 'cmdline', 'num_threads', 'status']),
                       key=lambda p: p.info['memory_percent'], reverse=True)[:TOP_N]

    # Collect the processes that exceed the threshold and haven't been traced recently
    processes_above_threshold = []
    current_time = time.time()

    for proc in processes:
        try:
            pid = proc.info['pid']
            memory_usage = proc.info['memory_percent']

            # Only trace if the process hasn't been traced recently or if memory usage increased significantly
            if (pid not in traced_processes or 
                (current_time - traced_processes[pid]['last_traced'] > REFRESH_INTERVAL) or 
                (memory_usage > traced_processes[pid]['memory_usage'] * 1.1)):  # Check for 10% increase in memory usage

                processes_above_threshold.append(proc)

                # Update traced processes dictionary
                traced_processes[pid] = {'last_traced': current_time, 'memory_usage': memory_usage}
        
        except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess):
            logger.warning(f"Could not access process {proc.info.get('name', 'Unknown')} (PID: {proc.info.get('pid', 'Unknown')})")

    # Create an aggregated trace with all the processes above the threshold
    if processes_above_threshold:
        with tracer.start_as_current_span(f"High Memory Usage: Threshold {threshold}%") as span:
            for proc in processes_above_threshold:
                span.add_event(
                    f"Process {proc.info['name']} (PID: {proc.info['pid']})",
                    attributes={
                        "pid": proc.info['pid'],
                        "name": proc.info['name'],
                        "memory_usage": proc.info['memory_percent'],
                        "command_line": ' '.join(proc.info['cmdline']) if proc.info['cmdline'] else 'N/A',
                        "num_threads": proc.info['num_threads'],
                        "status": proc.info['status']
                    }
                )
                logger.info(f"Process {proc.info['name']} (PID: {proc.info['pid']}) using {proc.info['memory_percent']}% memory")
    
if __name__ == '__main__':
    # Start the Prometheus HTTP server on port 8000
    start_http_server(8000)
    logger.info("Prometheus metrics available at http://localhost:8000/metrics")

    # Loop to monitor the system memory every 5 seconds
    while True:
        try:
            monitor_memory()
            time.sleep(5)
        except Exception as e:
            logger.error(f"Error occurred during memory monitoring: {str(e)}")
