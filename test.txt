Failover Strategy in Transformit
In the event of an error during execution, Transformit has a built-in failover mechanism to ensure that the system can recover from failures and continue processing without repeating successful tasks. This is done via a restart_config table that tracks the status of each task within every module.

How Failover Works:
Task Failure Detection
Each task within a module is monitored for its execution status. If a task fails due to any error (such as connection failure, service unavailability, or other issues), the failure is recorded in the restart_config table associated with that module.

Failover Process
Upon the next execution of the Transformit framework:

Tasks that were successfully completed in the previous execution are skipped.
Only the task(s) that failed during the last run are re-executed.
This ensures that no unnecessary repetition occurs, optimizing resource usage and reducing downtime.

Types of Failures Handled:
Connection Failures
If a data source or target is unavailable due to network or connection issues, the task is marked as failed, and the system will retry in the next execution.

Service Unavailability
If the external service (API, database, etc.) is down, the failure is recorded, and recovery occurs upon the next execution.

Other Errors
Any unforeseen runtime errors that prevent task completion are also recorded, triggering the failover mechanism.

Failover Example
Letâ€™s walk through an example of how failover works in the Polling module:

Initial Run:

Polling starts processing files from NFS.
Halfway through the process, the connection to Snowflake fails.
The failure is recorded in the restart_config table for the Polling module.
Failover on Next Run:

On the subsequent execution of Transformit, the system checks the restart_config table.
Polling skips the files that were already successfully uploaded.
It retries the failed task to upload the remaining files to Snowflake internal stages.
Benefits of Failover in Transformit
Efficiency: Only failed tasks are retried, reducing redundant work.
Resilience: Ensures that long-running processes can recover from interruptions.
Transparency: Logs and the restart_config table provide visibility into what failed and how it was recovered.
Conclusion
The failover mechanism in Transformit provides a robust way to handle failures without impacting the entire data pipeline. By skipping successfully completed tasks and focusing on failed tasks, it ensures that data ingestion and transformation processes can recover gracefully, reducing downtime and increasing reliability.

